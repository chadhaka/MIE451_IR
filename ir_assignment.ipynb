{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: IR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations\n",
    "* Put all your imports, and path constants in the next cells\n",
    "* Make sure ***MATERIALS_DIR*** points to the directory where you extracted the Zip file.\n",
    "* Make sure all your paths are **relative to ** ***MATERIALS_DIR*** and **NOT hard-coded** in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Windows\\ServiceProfiles\\\n",
      "[nltk_data]     LocalService\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "# Put all your imports here\n",
    "\n",
    "from whoosh import index, writing, qparser\n",
    "from whoosh.fields import Schema, TEXT, KEYWORD, ID, STORED\n",
    "from whoosh.analysis import *\n",
    "from whoosh.qparser import QueryParser\n",
    "import os, os.path\n",
    "import shutil\n",
    "# NLTK Library\n",
    "import nltk\n",
    "from nltk.stem import *\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MATERIALS_DIR = r\"C:\\DSS_Fall2017_Assign2\"\n",
    "#\n",
    "# Put other path constants here\n",
    "#\n",
    "DOCUMENTS_DIR = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\government\\documents\")\n",
    "INDEX_DIR = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\government\\index1\")\n",
    "QUER_FILE = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\government\\topics\\gov.topics\")\n",
    "QRELS_FILE = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\government\\qrels\\gov.qrels\")\n",
    "OUTPUT_FILE = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\government\\myres\")\n",
    "TREC_EVAL = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\trec_eval\\trec_eval.exe\")\n",
    "INDEX_DIR2 = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\government\\index2\")\n",
    "OUTPUT_FILE2 = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\government\\myres2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomFilter(Filter):\n",
    "    is_morph = True\n",
    "    def __init__(self, filterFunc, *args, **kwargs):\n",
    "        self.customFilter = filterFunc\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "    def __eq__(self):\n",
    "        return (other\n",
    "                and self.__class__ is other.__class__)\n",
    "    def __call__(self, tokens):\n",
    "        for t in tokens:\n",
    "            if t.mode == 'query': # if called by query parser\n",
    "                t.text = self.customFilter(t.text, *self.args, **self.kwargs)\n",
    "                yield t\n",
    "            else: # == 'index' if called by indexer\n",
    "                t.text = self.customFilter(t.text, *self.args, **self.kwargs)\n",
    "                yield t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Provide your text answers in the following two markdown cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 (a): Provide answer to Q1 (a) here [markdown cell]\n",
    "\n",
    "recip_rank\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 (b): Provide answer to Q1 (b) here [markdown cell]\n",
    "Government websites are usually customer focused, where the person is only interested in finding the information they are searching for. Usually this information can be retrievied from one relevant document.\n",
    "\n",
    "Thus the higher the relevant document ranks, the more satisfied the customer is making the search engine better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 (a): Write your code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put your code for creating the index here (you can add more cells).\n",
    "# Make sure you save the final index in the variable INDEX_Q2, your query parser in QP_Q2, and your searcher in SEARCHER_Q2\n",
    "\n",
    "mySchema = Schema(file_path = ID(stored=True),\n",
    "                  file_content = TEXT(analyzer = RegexTokenizer()))\n",
    "\n",
    "if os.path.isdir(INDEX_DIR):\n",
    "    shutil.rmtree(INDEX_DIR)\n",
    "\n",
    "# create the directory for the index\n",
    "os.makedirs(INDEX_DIR)\n",
    "\n",
    "# create index\n",
    "myIndex = index.create_in(INDEX_DIR, mySchema)\n",
    "\n",
    "filesToIndex = []\n",
    "for root, dirs, files in os.walk(DOCUMENTS_DIR):\n",
    "    filePaths = [os.path.join(root, fileName) for fileName in files if not fileName.startswith('.')]\n",
    "    filesToIndex.extend(filePaths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already indexed: 1\n",
      "already indexed: 1001\n",
      "already indexed: 2001\n",
      "already indexed: 3001\n",
      "already indexed: 4001\n",
      "done indexing.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "myWriter = writing.BufferedWriter(myIndex, period=60, limit=1000)\n",
    "try:\n",
    "    # write each file to index\n",
    "    for docNum, filePath in enumerate(filesToIndex):\n",
    "        with open(filePath, \"r\", encoding=\"utf8\") as f:\n",
    "            fileContent = f.read()\n",
    "            myWriter.add_document(file_path = filePath,\n",
    "                                  file_content = fileContent)\n",
    "            \n",
    "            if (docNum % 1000 == 0):\n",
    "                print(\"already indexed:\", docNum+1)\n",
    "    print(\"done indexing.\")\n",
    "\n",
    "finally:\n",
    "    # save the index\n",
    "    myWriter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "myQueryParser = QueryParser(\"file_content\", schema=myIndex.schema)\n",
    "mySearcher = myIndex.searcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load topic file - a list of topics(search phrases) used for evalutation\n",
    "topicsFile = open(QUER_FILE,\"r\")\n",
    "topics = topicsFile.read().splitlines()\n",
    "#print(topics)\n",
    "\n",
    "# create an output file to which we'll write our results\n",
    "outputTRECFile = open(OUTPUT_FILE, \"w\")\n",
    "\n",
    "# for each evaluated topic:\n",
    "# build a query and record the results in the file in TREC_EVAL format\n",
    "for topic in topics:\n",
    "    topic_id, topic_phrase = tuple(topic.split(\" \", 1))\n",
    "    topicQuery = myQueryParser.parse(topic_phrase)\n",
    "    topicResults = mySearcher.search(topicQuery, limit=None)\n",
    "    for (docnum, result) in enumerate(topicResults):\n",
    "        score = topicResults.score(docnum)\n",
    "        outputTRECFile.write(\"%s Q0 %s %d %lf test\\n\" % (topic_id, os.path.basename(result[\"file_path\"]), docnum, score))\n",
    "\n",
    "# close the topic and results file\n",
    "outputTRECFile.close()\n",
    "topicsFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INDEX_Q2 = myIndex\n",
    "QP_Q2 = myQueryParser\n",
    "SEARCHER_Q2 = mySearcher\n",
    "\n",
    "#INDEX_Q2 = None # Replace None with your index for Q2\n",
    "#QP_Q2 = None # Replace None with your query parser for Q2\n",
    "#SEARCHER_Q2 = None # Replace None with your searcher for Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###!cat $QRELS_FILE\n",
    "###!cat $OUTPUT_FILE\n",
    "###!$TREC_EVAL -q $QRELS_FILE $OUTPUT_FILE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 (b): Provide answer to Q2 (b) here [markdown cell]\n",
    "\n",
    "For recip_rank the average score was 0.2196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 (c): Provide answer to Q2(c) here [markdown cell]\n",
    "Topics it did very well:\n",
    "18\n",
    "24\n",
    "Topics it did poorly on:\n",
    "2,28,6,79\n",
    "\n",
    "Is a bad case where the score is 0 or >0 but low?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 (a): Provide answer to Q3 (a) here [markdown cell]\n",
    "Chosen Topic: Topic #4 - \"wireless communications\"\n",
    "\n",
    "For this topic there were a total of 4 relevant documents but the original query retreived 12 documents. Of those retreived there was 1 True Positive case and 11 False Positive cases. As there were 4 relevant documents of which only 1 was True Positive, the rest of the 3 documents are classified as False Negative Cases.\n",
    "\n",
    "An example of each is given below:\n",
    "\n",
    "False Positive Case: In the Output_File produced above, Document G00-85-1525415 received a score of ~13.4 and ranked 2nd after using Whoosh's baseline system. However the Qrels file gives a relevance of 0 for topic #4. Thus the system assumed the document to be relevant even though it shouldn't have.\n",
    "\n",
    "False Negative Case: In the Qrels file, document G00-36-1275993 is considered relevant for topic #4 based off human judgement. However in the OutputFile produced above this document does not receive any score or rank for this topic. This means the Whoosh system considered this document to be irrelevant for topic #4 which isn't actually the case.\n",
    "\n",
    "Using Text Analyzers such as a stem, stop or lowercase filter prior to using the whoosh system would help improve performance. The data would be cleaned of 'filler' words, ignore cases and only partial words to increase the likelihood of matching documents and finding relevant ones. \n",
    "Another change I would undertake would be to search for each word instead of the whole phrase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 (b): Write your code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code for creating the index here (you can add more cells).\n",
    "# Make sure you save the final index in the variable INDEX_Q3, your query parser in QP_Q3, and your searcher in SEARCHER_Q3\n",
    "\n",
    "myAnalyzer = RegexTokenizer() | LowercaseFilter() | IntraWordFilter() | StopFilter() | CustomFilter(LancasterStemmer().stem)\n",
    "\n",
    "mySchema2 = Schema(file_path = ID(stored=True),\n",
    "                  file_content = TEXT(analyzer = myAnalyzer))\n",
    "\n",
    "if os.path.isdir(INDEX_DIR2):\n",
    "    shutil.rmtree(INDEX_DIR2)\n",
    "\n",
    "\n",
    "# create the directory for the index\n",
    "os.makedirs(INDEX_DIR2)\n",
    "\n",
    "# create index\n",
    "myIndex2 = index.create_in(INDEX_DIR2, mySchema2)\n",
    "\n",
    "filesToIndex = []\n",
    "for root, dirs, files in os.walk(DOCUMENTS_DIR):\n",
    "    filePaths = [os.path.join(root, fileName) for fileName in files if not fileName.startswith('.')]\n",
    "    filesToIndex.extend(filePaths)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already indexed: 1\n",
      "already indexed: 1001\n",
      "already indexed: 2001\n",
      "already indexed: 3001\n",
      "already indexed: 4001\n",
      "done indexing.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "myWriter2 = writing.BufferedWriter(myIndex2, period=60, limit=1000)\n",
    "try:\n",
    "    # write each file to index\n",
    "    for docNum, filePath in enumerate(filesToIndex):\n",
    "        with open(filePath, \"r\", encoding=\"utf8\") as f:\n",
    "            fileContent = f.read()\n",
    "            myWriter2.add_document(file_path = filePath,\n",
    "                                  file_content = fileContent)\n",
    "            \n",
    "            if (docNum % 1000 == 0):\n",
    "                print(\"already indexed:\", docNum+1)\n",
    "    print(\"done indexing.\")\n",
    "\n",
    "finally:\n",
    "    # save the index\n",
    "    myWriter2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "myQueryParser2 = qparser.QueryParser(\"file_content\", schema=myIndex2.schema,group=qparser.OrGroup)\n",
    "mySearcher2 = myIndex2.searcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load topic file - a list of topics(search phrases) used for evalutation\n",
    "topicsFile = open(QUER_FILE,\"r\")\n",
    "topics = topicsFile.read().splitlines()\n",
    "    \n",
    "# create an output file to which we'll write our results\n",
    "outputTRECFile2 = open(OUTPUT_FILE2, \"w\")\n",
    "\n",
    "# for each evaluated topic:\n",
    "# build a query and record the results in the file in TREC_EVAL format\n",
    "for topic in topics:\n",
    "    topic_id, topic_phrase = tuple(topic.split(\" \", 1))\n",
    "  #  print(topic_phrase)\n",
    "    topicQuery = myQueryParser2.parse(topic_phrase)\n",
    "   # print(topicQuery)\n",
    "    topicResults = mySearcher2.search(topicQuery, limit=None)\n",
    "    for (docnum, result) in enumerate(topicResults):\n",
    "        score = topicResults.score(docnum)\n",
    "        outputTRECFile2.write(\"%s Q0 %s %d %lf test\\n\" % (topic_id, os.path.basename(result[\"file_path\"]), docnum, score))\n",
    "\n",
    "# close the topic and results file\n",
    "outputTRECFile2.close()\n",
    "topicsFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INDEX_Q3 = myIndex2 # Replace None with your index for Q3\n",
    "QP_Q3 = myQueryParser2 # Replace None with your query parser for Q3\n",
    "SEARCHER_Q3 = mySearcher2 # Replace None with your searcher for Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###!cat $OUTPUT_FILE2\n",
    "###!$TREC_EVAL -q $QRELS_FILE $OUTPUT_FILE2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 (c): Provide answer to Q3 (c) here [markdown cell]\n",
    "\n",
    "Modifications: I used an additional 4 Text Analyzers and sent the Query in using an OR rather than the default AND. This way documents were searched for each word rather than the whole phrase.\n",
    "\n",
    "Improvements: Comparing the selected measure recip_rank with the previous results, there are a total of 13 topics with an improved or equal result and overall the average results for this measure improved by 113%.\n",
    "For Topic 4 the number of False Negative cases dropped to zero, however the false positives increased drastically to ~900 (this can be attributed to using OR). However the True Positives that were returned ranked the highest in the retreival.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 (d): Provide answer to Q3 (d) here [markdown cell]\n",
    "Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 (e): Provide answer to Q3 (e) here [markdown cell]\n",
    "Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 (f): Provide answer to Q3 (f) here [markdown cell]\n",
    "It was good. 87% of the queries improved their score on the recip_rank measure, meaning the relevant documents ranked higher. For a user on a government website they will be satisfied if they can get their information on the first few results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (Graduate Students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GRAD_STUDENT = False # change to True if you are a grad student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 (a): Provide answer to Q4 (a) here [markdown cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 (b): Write your code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put your code for creating the index here (you can add more cells).\n",
    "# Make sure you save the final index in the variable INDEX_Q4, your query parser in QP_Q4, and your searcher in SEARCHER_Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INDEX_Q4 = None # Replace None with your index for Q4\n",
    "QP_Q4 = None # Replace None with your query parser for Q4\n",
    "SEARCHER_Q4 = None # Replace None with your searcher for Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 (c): Provide answer to Q4 (a) here [markdown cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 (d): Provide answer to Q4 (a) here [markdown cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 (e): Provide answer to Q4 (a) here [markdown cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 (f): Provide answer to Q4 (a) here [markdown cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run the following cells to make sure your code returns the correct value types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from whoosh.index import FileIndex\n",
    "from whoosh.qparser import QueryParser\n",
    "from whoosh.searching import Searcher\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths validated\n"
     ]
    }
   ],
   "source": [
    "assert \"MATERIALS_DIR\" in globals(), \"variable MATERIALS_DIR does not exists\"\n",
    "assert(os.path.isdir(os.path.join(MATERIALS_DIR))), \"MATERIALS_DIR folder does not exists\"\n",
    "assert(os.path.isdir(os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\"))), \"invalid folder structure\"\n",
    "assert(os.path.isdir(os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\government\\documents\"))), \"invalid folder structure\"\n",
    "print(\"Paths validated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2 Types Validated\n"
     ]
    }
   ],
   "source": [
    "assert(isinstance(INDEX_Q2, FileIndex)), \"Index Type\"\n",
    "assert(isinstance(QP_Q2, QueryParser)), \"Query Parser Type\"\n",
    "assert(isinstance(SEARCHER_Q2, Searcher)), \"Searcher Type\"\n",
    "print(\"Q2 Types Validated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3 Types Validated\n"
     ]
    }
   ],
   "source": [
    "assert(isinstance(INDEX_Q3, FileIndex)), \"Index Type\"\n",
    "assert(isinstance(QP_Q3, QueryParser)), \"Query Parser Type\"\n",
    "assert(isinstance(SEARCHER_Q3, Searcher)), \"Searcher Type\"\n",
    "print(\"Q3 Types Validated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 Validation (Graduate Students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4 Types Validated\n"
     ]
    }
   ],
   "source": [
    "assert((not GRAD_STUDENT) or isinstance(INDEX_Q4, FileIndex)), \"Index Type\"\n",
    "assert((not GRAD_STUDENT) or isinstance(QP_Q4, QueryParser)), \"Query Parser Type\"\n",
    "assert((not GRAD_STUDENT) or isinstance(SEARCHER_Q4, Searcher)), \"Searcher Type\"\n",
    "print(\"Q4 Types Validated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
