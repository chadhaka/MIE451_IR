{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: IR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations\n",
    "* Put all your imports, and path constants in the next cells\n",
    "* Make sure ***MATERIALS_DIR*** points to the directory where you extracted the Zip file.\n",
    "* Make sure all your paths are **relative to ** ***MATERIALS_DIR*** and **NOT hard-coded** in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# Put all your imports here\n",
    "\n",
    "from whoosh import index, writing, qparser\n",
    "from whoosh.fields import Schema, TEXT, KEYWORD, ID, STORED\n",
    "from whoosh.analysis import *\n",
    "#from whoosh.qparser import QueryParser\n",
    "import os, os.path\n",
    "import shutil\n",
    "# NLTK Library\n",
    "import nltk\n",
    "from nltk.stem import *\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MATERIALS_DIR = r\"C:\\DSS_Fall2017_Assign2\"\n",
    "#\n",
    "# Put other path constants here\n",
    "#\n",
    "DOCUMENTS_DIR = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\government\\documents\")\n",
    "INDEX_DIR = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\government\\index1\")\n",
    "QUER_FILE = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\government\\topics\\gov.topics\")\n",
    "QRELS_FILE = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\government\\qrels\\gov.qrels\")\n",
    "OUTPUT_FILE = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\government\\myres\")\n",
    "TREC_EVAL = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\trec_eval\\trec_eval.exe\")\n",
    "INDEX_DIR2 = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\government\\index2\")\n",
    "OUTPUT_FILE2 = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\government\\myres2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomFilter(Filter):\n",
    "    is_morph = True\n",
    "    def __init__(self, filterFunc, *args, **kwargs):\n",
    "        self.customFilter = filterFunc\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "    def __eq__(self):\n",
    "        return (other\n",
    "                and self.__class__ is other.__class__)\n",
    "    def __call__(self, tokens):\n",
    "        for t in tokens:\n",
    "            if t.mode == 'query': # if called by query parser\n",
    "                t.text = self.customFilter(t.text, *self.args, **self.kwargs)\n",
    "                yield t\n",
    "            else: # == 'index' if called by indexer\n",
    "                t.text = self.customFilter(t.text, *self.args, **self.kwargs)\n",
    "                yield t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for trec_eval measures - TO BE DELETED\n",
    "!$TREC_EVAL -h -m official\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Provide your text answers in the following two markdown cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 (a): Provide answer to Q1 (a) here [markdown cell]\n",
    "\n",
    "recip_rank\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 (b): Provide answer to Q1 (b) here [markdown cell]\n",
    "Government websites are usually customer focused, where the person is only interested in finding the information they are searching for. Usually this information can be retrievied from one relevant document.\n",
    "\n",
    "Thus the higher the relevant document ranks, the more satisfied the customer is making the search engine better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 (a): Write your code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put your code for creating the index here (you can add more cells).\n",
    "# Make sure you save the final index in the variable INDEX_Q2, your query parser in QP_Q2, and your searcher in SEARCHER_Q2\n",
    "\n",
    "mySchema = Schema(file_path = ID(stored=True),\n",
    "                  file_content = TEXT(analyzer = RegexTokenizer()))\n",
    "\n",
    "if os.path.isdir(INDEX_DIR):\n",
    "    shutil.rmtree(INDEX_DIR)\n",
    "\n",
    "# create the directory for the index\n",
    "os.makedirs(INDEX_DIR)\n",
    "\n",
    "# create index\n",
    "myIndex = index.create_in(INDEX_DIR, mySchema)\n",
    "\n",
    "filesToIndex = []\n",
    "for root, dirs, files in os.walk(DOCUMENTS_DIR):\n",
    "    filePaths = [os.path.join(root, fileName) for fileName in files if not fileName.startswith('.')]\n",
    "    filesToIndex.extend(filePaths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "myWriter = writing.BufferedWriter(myIndex, period=60, limit=1000)\n",
    "try:\n",
    "    # write each file to index\n",
    "    for docNum, filePath in enumerate(filesToIndex):\n",
    "        with open(filePath, \"r\", encoding=\"utf8\") as f:\n",
    "            fileContent = f.read()\n",
    "            myWriter.add_document(file_path = filePath,\n",
    "                                  file_content = fileContent)\n",
    "            \n",
    "            if (docNum % 1000 == 0):\n",
    "                print(\"already indexed:\", docNum+1)\n",
    "    print(\"done indexing.\")\n",
    "\n",
    "finally:\n",
    "    # save the index\n",
    "    myWriter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "myQueryParser = QueryParser(\"file_content\", schema=myIndex.schema)\n",
    "mySearcher = myIndex.searcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load topic file - a list of topics(search phrases) used for evalutation\n",
    "topicsFile = open(QUER_FILE,\"r\")\n",
    "topics = topicsFile.read().splitlines()\n",
    "print(topics)\n",
    "\n",
    "# create an output file to which we'll write our results\n",
    "outputTRECFile = open(OUTPUT_FILE, \"w\")\n",
    "\n",
    "# for each evaluated topic:\n",
    "# build a query and record the results in the file in TREC_EVAL format\n",
    "for topic in topics:\n",
    "    topic_id, topic_phrase = tuple(topic.split(\" \", 1))\n",
    "    topicQuery = myQueryParser.parse(topic_phrase)\n",
    "    topicResults = mySearcher.search(topicQuery, limit=None)\n",
    "    for (docnum, result) in enumerate(topicResults):\n",
    "        score = topicResults.score(docnum)\n",
    "        outputTRECFile.write(\"%s Q0 %s %d %lf test\\n\" % (topic_id, os.path.basename(result[\"file_path\"]), docnum, score))\n",
    "\n",
    "# close the topic and results file\n",
    "outputTRECFile.close()\n",
    "topicsFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INDEX_Q2 = myIndex\n",
    "QP_Q2 = myQueryParser\n",
    "SEARCHER_Q2 = mySearcher\n",
    "\n",
    "#INDEX_Q2 = None # Replace None with your index for Q2\n",
    "#QP_Q2 = None # Replace None with your query parser for Q2\n",
    "#SEARCHER_Q2 = None # Replace None with your searcher for Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat $QRELS_FILE\n",
    "### Relevant or Not - human judgement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat $OUTPUT_FILE\n",
    "### My results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!$TREC_EVAL -q $QRELS_FILE $OUTPUT_FILE\n",
    "###Comparison of the two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 (b): Provide answer to Q2 (b) here [markdown cell]\n",
    "\n",
    "For recip_rank the average score was 0.2196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 (c): Provide answer to Q2(c) here [markdown cell]\n",
    "Topics it did very well:\n",
    "18\n",
    "24\n",
    "Topics it did poorly on:\n",
    "2,28,6,79\n",
    "\n",
    "Is a bad case where the score is 0 or >0 but low?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 (a): Provide answer to Q3 (a) here [markdown cell]\n",
    "Chosen Topic: Topic #4 - \"*to be filled in*\"\n",
    "\n",
    "For this topic there were a total of 4 relevant documents but the original query retreived 12 documents. Of those retreived there was 1 True Positive case and 11 False Positive cases. As there were 4 relevant documents of which only 1 was True Positive, the rest of the 3 documents are classified as False Negative Cases.\n",
    "\n",
    "An example of each is given below:\n",
    "\n",
    "False Positive Case: In the Output_File produced above, Document G00-85-1525415 received a score of ~13.4 and ranked 2nd after using Whoosh's baseline system. However the Qrels file gives a relevance of 0 for topic #4. Thus the system assumed the document to be relevant even though it shouldn't have.\n",
    "\n",
    "False Negative Case: In the Qrels file, document G00-36-1275993 is considered relevant for topic #4 based off human judgement. However in the OutputFile produced above this document does not receive any score or rank for this topic. This means the Whoosh system considered this document to be irrelevant for topic #4 which isn't actually the case.\n",
    "\n",
    "Using Text Analyzers such as a stem, stop or lowercase filter prior to using the whoosh system would help improve performance. The data would be cleaned of 'filler' words, ignore cases and only partial words to increase the likelihood of matching documents and finding relevant ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 (b): Write your code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###GET RID OF THIS CELL\n",
    "\n",
    "import re\n",
    "myAnalyzer = RegexTokenizer() | LowercaseFilter() | IntraWordFilter() | StopFilter() |  CustomFilter(SnowballStemmer(\"english\").stem)\n",
    "topicsFile = open(QUER_FILE,\"r\")\n",
    "topics = topicsFile.read().splitlines()\n",
    "topics2 = []\n",
    "for topic1 in topics:\n",
    "    topic1 = re.sub(r'\\d+', '', topic1)\n",
    "    topics2.append(topic1)\n",
    "    print(topic1)\n",
    "    print([token.text for token in myAnalyzer(topic1)])\n",
    "    print(\"\\n\")\n",
    "print(topics2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code for creating the index here (you can add more cells).\n",
    "# Make sure you save the final index in the variable INDEX_Q3, your query parser in QP_Q3, and your searcher in SEARCHER_Q3\n",
    "\n",
    "myAnalyzer = RegexTokenizer() | LowercaseFilter() | IntraWordFilter() | StopFilter() | CustomFilter(SnowballStemmer(\"english\").stem)\n",
    "\n",
    "mySchema2 = Schema(file_path = ID(stored=True),\n",
    "                  file_content = TEXT(analyzer = myAnalyzer))\n",
    "\n",
    "if os.path.isdir(INDEX_DIR2):\n",
    "    shutil.rmtree(INDEX_DIR2)\n",
    "\n",
    "\n",
    "# create the directory for the index\n",
    "os.makedirs(INDEX_DIR2)\n",
    "\n",
    "# create index\n",
    "myIndex2 = index.create_in(INDEX_DIR2, mySchema2)\n",
    "\n",
    "filesToIndex = []\n",
    "for root, dirs, files in os.walk(DOCUMENTS_DIR):\n",
    "    filePaths = [os.path.join(root, fileName) for fileName in files if not fileName.startswith('.')]\n",
    "    filesToIndex.extend(filePaths)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "myWriter2 = writing.BufferedWriter(myIndex2, period=60, limit=1000)\n",
    "try:\n",
    "    # write each file to index\n",
    "    for docNum, filePath in enumerate(filesToIndex):\n",
    "        with open(filePath, \"r\", encoding=\"utf8\") as f:\n",
    "            fileContent = f.read()\n",
    "            myWriter2.add_document(file_path = filePath,\n",
    "                                  file_content = fileContent)\n",
    "            \n",
    "            if (docNum % 1000 == 0):\n",
    "                print(\"already indexed:\", docNum+1)\n",
    "    print(\"done indexing.\")\n",
    "\n",
    "finally:\n",
    "    # save the index\n",
    "    myWriter2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myQueryParser2 = qparser.QueryParser(\"file_content\", schema=myIndex2.schema,group=qparser.OrGroup)\n",
    "mySearcher2 = myIndex2.searcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load topic file - a list of topics(search phrases) used for evalutation\n",
    "topicsFile = open(QUER_FILE,\"r\")\n",
    "topics = topicsFile.read().splitlines()\n",
    "    \n",
    "# create an output file to which we'll write our results\n",
    "outputTRECFile2 = open(OUTPUT_FILE2, \"w\")\n",
    "\n",
    "# for each evaluated topic:\n",
    "# build a query and record the results in the file in TREC_EVAL format\n",
    "for topic in topics:\n",
    "    topic_id, topic_phrase = tuple(topic.split(\" \", 1))\n",
    "  #  print(topic_phrase)\n",
    "    topicQuery = myQueryParser2.parse(topic_phrase)\n",
    "   # print(topicQuery)\n",
    "    topicResults = mySearcher2.search(topicQuery, limit=None)\n",
    "    for (docnum, result) in enumerate(topicResults):\n",
    "        score = topicResults.score(docnum)\n",
    "        outputTRECFile2.write(\"%s Q0 %s %d %lf test\\n\" % (topic_id, os.path.basename(result[\"file_path\"]), docnum, score))\n",
    "\n",
    "# close the topic and results file\n",
    "outputTRECFile2.close()\n",
    "topicsFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INDEX_Q3 = myIndex2 # Replace None with your index for Q3\n",
    "QP_Q3 = myQueryParser2 # Replace None with your query parser for Q3\n",
    "SEARCHER_Q3 = mySearcher2 # Replace None with your searcher for Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat $OUTPUT_FILE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!$TREC_EVAL -q $QRELS_FILE $OUTPUT_FILE2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 (c): Provide answer to Q3 (c) here [markdown cell]\n",
    "\n",
    "I used an additional 5 Text Analyzers:\n",
    "1) LowercaseFilter() - Used this to make all the words in the query lowercase\n",
    "2) IntraWordFilter() - Used this to remove any punctuation within the query\n",
    "3) StopFilter() - Used this to removes any filler words such as 'and' 'are' etc. that were present in the queries \n",
    "4) CustomFilter(SnowballStemmer(\"english\").stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 (d): Provide answer to Q3 (d) here [markdown cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 (e): Provide answer to Q3 (e) here [markdown cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 (f): Provide answer to Q3 (f) here [markdown cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (Graduate Students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GRAD_STUDENT = False # change to True if you are a grad student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 (a): Provide answer to Q4 (a) here [markdown cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 (b): Write your code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put your code for creating the index here (you can add more cells).\n",
    "# Make sure you save the final index in the variable INDEX_Q4, your query parser in QP_Q4, and your searcher in SEARCHER_Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INDEX_Q4 = None # Replace None with your index for Q4\n",
    "QP_Q4 = None # Replace None with your query parser for Q4\n",
    "SEARCHER_Q4 = None # Replace None with your searcher for Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 (c): Provide answer to Q4 (a) here [markdown cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 (d): Provide answer to Q4 (a) here [markdown cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 (e): Provide answer to Q4 (a) here [markdown cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 (f): Provide answer to Q4 (a) here [markdown cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run the following cells to make sure your code returns the correct value types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from whoosh.index import FileIndex\n",
    "from whoosh.qparser import QueryParser\n",
    "from whoosh.searching import Searcher\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert \"MATERIALS_DIR\" in globals(), \"variable MATERIALS_DIR does not exists\"\n",
    "assert(os.path.isdir(os.path.join(MATERIALS_DIR))), \"MATERIALS_DIR folder does not exists\"\n",
    "assert(os.path.isdir(os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\"))), \"invalid folder structure\"\n",
    "assert(os.path.isdir(os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\government\\documents\"))), \"invalid folder structure\"\n",
    "print(\"Paths validated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(isinstance(INDEX_Q2, FileIndex)), \"Index Type\"\n",
    "assert(isinstance(QP_Q2, QueryParser)), \"Query Parser Type\"\n",
    "assert(isinstance(SEARCHER_Q2, Searcher)), \"Searcher Type\"\n",
    "print(\"Q2 Types Validated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(isinstance(INDEX_Q3, FileIndex)), \"Index Type\"\n",
    "assert(isinstance(QP_Q3, QueryParser)), \"Query Parser Type\"\n",
    "assert(isinstance(SEARCHER_Q3, Searcher)), \"Searcher Type\"\n",
    "print(\"Q3 Types Validated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 Validation (Graduate Students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert((not GRAD_STUDENT) or isinstance(INDEX_Q4, FileIndex)), \"Index Type\"\n",
    "assert((not GRAD_STUDENT) or isinstance(QP_Q4, QueryParser)), \"Query Parser Type\"\n",
    "assert((not GRAD_STUDENT) or isinstance(SEARCHER_Q4, Searcher)), \"Searcher Type\"\n",
    "print(\"Q4 Types Validated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
